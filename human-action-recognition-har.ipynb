{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Environment Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-11T22:03:26.148745Z","iopub.status.busy":"2024-01-11T22:03:26.148349Z","iopub.status.idle":"2024-01-11T22:03:38.628916Z","shell.execute_reply":"2024-01-11T22:03:38.627913Z","shell.execute_reply.started":"2024-01-11T22:03:26.148711Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Resources will be available on local/ directory\n","\n","import os\n","import requests, zipfile, io, os, shutil, subprocess\n","github_repo = 'alejoUdeAMl/ml_har_v1'\n","zip_file_url = 'https://github.com/alejoUdeAMl/ml_har_v1/archive/main.zip'\n","if not os.path.exists(\"local\"):\n","    print(\"replicating local resources\")\n","    dirname = github_repo.split(\"/\")[-1] + \"-main/\"\n","    if os.path.exists(dirname):\n","        shutil.rmtree(dirname)\n","    r = requests.get(zip_file_url)\n","    z = zipfile.ZipFile(io.BytesIO(r.content))\n","    z.extractall()\n","    if os.path.exists(\"local\"):\n","        shutil.rmtree(\"local\")\n","    if os.path.exists(dirname + \"/content/local\"):\n","        shutil.move(dirname + \"/content/local\", \"local\")\n","    elif os.path.exists(dirname + \"/local\"):\n","        shutil.move(dirname + \"/local\", \"local\")\n","    shutil.rmtree(dirname)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Human Action Recognition (HAR)\n","* Human activity recognition, or HAR for short, is a broad field of study concerned with identifying the specific movement or action of a person based on sensor data.\n","* Movements are often typical activities performed indoors, such as walking, talking, standing, and sitting\n","\n","\n","# Why it is important ?\n","* Human activity recognition plays a significant role in human-to-human interaction and interpersonal relations.\n","* Because it provides information about the identity of a person, their personality, and psychological state, it is difficult to extract.\n","* The human ability to recognize another personâ€™s activities is one of the main subjects of study of the scientific areas of computer vision and machine learning. As a result of this research, many applications, including video surveillance systems, human-computer interaction, and robotics for human behavior characterization, require a multiple activity recognition system.\n","* On my research I will need to clasify patients actions on a monitored environment."]},{"cell_type":"markdown","metadata":{},"source":["# 3. Importing libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:14:27.869261Z","iopub.status.busy":"2024-01-11T22:14:27.868899Z","iopub.status.idle":"2024-01-11T22:14:28.017199Z","shell.execute_reply":"2024-01-11T22:14:28.01625Z","shell.execute_reply.started":"2024-01-11T22:14:27.869236Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from keras.models import Sequential\n","from keras.layers import Activation, Flatten, Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","from PIL import Image\n","import matplotlib.image as img\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Getting the path and Loading the data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:14:44.26215Z","iopub.status.busy":"2024-01-11T22:14:44.2613Z","iopub.status.idle":"2024-01-11T22:14:44.282774Z","shell.execute_reply":"2024-01-11T22:14:44.282003Z","shell.execute_reply.started":"2024-01-11T22:14:44.262117Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(\"local/Human Action Recognition/Training_set.csv\")\n","test_data = pd.read_csv(\"local/Human Action Recognition/Testing_set.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:14:49.655157Z","iopub.status.busy":"2024-01-11T22:14:49.654239Z","iopub.status.idle":"2024-01-11T22:14:49.720266Z","shell.execute_reply":"2024-01-11T22:14:49.719302Z","shell.execute_reply.started":"2024-01-11T22:14:49.655126Z"},"trusted":true},"outputs":[],"source":["train_fol = glob.glob(\"local/Human Action Recognition/train/*\") \n","test_fol = glob.glob(\"local/Human Action Recognition/test/*\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:14:58.954598Z","iopub.status.busy":"2024-01-11T22:14:58.953972Z","iopub.status.idle":"2024-01-11T22:14:58.966431Z","shell.execute_reply":"2024-01-11T22:14:58.965284Z","shell.execute_reply.started":"2024-01-11T22:14:58.954568Z"},"trusted":true},"outputs":[],"source":["train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:15:11.420153Z","iopub.status.busy":"2024-01-11T22:15:11.419783Z","iopub.status.idle":"2024-01-11T22:15:11.429603Z","shell.execute_reply":"2024-01-11T22:15:11.4287Z","shell.execute_reply.started":"2024-01-11T22:15:11.420125Z"},"trusted":true},"outputs":[],"source":["train_data.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:15:56.035Z","iopub.status.busy":"2024-01-11T22:15:56.034271Z","iopub.status.idle":"2024-01-11T22:15:56.08957Z","shell.execute_reply":"2024-01-11T22:15:56.088597Z","shell.execute_reply.started":"2024-01-11T22:15:56.034966Z"},"trusted":true},"outputs":[],"source":["import plotly.express as px\n","HAR = train_data.label.value_counts()\n","fig = px.pie(train_data, values=HAR.values, names=HAR.index, title='Pie of Human Actions')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:16:10.588301Z","iopub.status.busy":"2024-01-11T22:16:10.587427Z","iopub.status.idle":"2024-01-11T22:16:10.592625Z","shell.execute_reply":"2024-01-11T22:16:10.591698Z","shell.execute_reply.started":"2024-01-11T22:16:10.588264Z"},"trusted":true},"outputs":[],"source":["filename = train_data['filename']\n","\n","situation = train_data['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:16:18.011412Z","iopub.status.busy":"2024-01-11T22:16:18.011025Z","iopub.status.idle":"2024-01-11T22:16:18.019906Z","shell.execute_reply":"2024-01-11T22:16:18.018873Z","shell.execute_reply.started":"2024-01-11T22:16:18.011382Z"},"trusted":true},"outputs":[],"source":["filename"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["situation"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Display random image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:21:18.967708Z","iopub.status.busy":"2024-01-11T22:21:18.967304Z","iopub.status.idle":"2024-01-11T22:21:18.974521Z","shell.execute_reply":"2024-01-11T22:21:18.973338Z","shell.execute_reply.started":"2024-01-11T22:21:18.967679Z"},"trusted":true},"outputs":[],"source":["def displaying_random_images():\n","    num = random.randint(1, 10000)\n","    imgg = \"Image_{}.jpg\".format(num)\n","    train = \"local/Human Action Recognition/train/\"\n","    if os.path.exists(train + imgg):\n","        testImage = img.imread(train + imgg)\n","        plt.imshow(testImage)\n","        plt.title(\"{}\".format(train_data.loc[train_data['filename'] == \"{}\".format(imgg), 'label'].item()))\n","\n","    else:\n","        print(\"File Path not found \\nSkipping the file!!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:21:22.151306Z","iopub.status.busy":"2024-01-11T22:21:22.150944Z","iopub.status.idle":"2024-01-11T22:21:22.63672Z","shell.execute_reply":"2024-01-11T22:21:22.634447Z","shell.execute_reply.started":"2024-01-11T22:21:22.151278Z"},"trusted":true},"outputs":[],"source":["displaying_random_images()"]},{"cell_type":"markdown","metadata":{},"source":["# 6. Resizing images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:23:29.40518Z","iopub.status.busy":"2024-01-11T22:23:29.404772Z","iopub.status.idle":"2024-01-11T22:24:52.18708Z","shell.execute_reply":"2024-01-11T22:24:52.185933Z","shell.execute_reply.started":"2024-01-11T22:23:29.405146Z"},"trusted":true},"outputs":[],"source":["img_data = []\n","img_label = []\n","length = len(train_fol)\n","for i in (range(len(train_fol)-1)):\n","    t = 'local/Human Action Recognition/train/' + filename[i]    \n","    temp_img = Image.open(t)\n","    img_data.append(np.asarray(temp_img.resize((240,240))))\n","    img_label.append(situation[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:25:36.550293Z","iopub.status.busy":"2024-01-11T22:25:36.549714Z","iopub.status.idle":"2024-01-11T22:25:36.554436Z","shell.execute_reply":"2024-01-11T22:25:36.553482Z","shell.execute_reply.started":"2024-01-11T22:25:36.550264Z"},"trusted":true},"outputs":[],"source":["img_shape= (240,240,3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:31:34.208312Z","iopub.status.busy":"2024-01-11T22:31:34.207929Z","iopub.status.idle":"2024-01-11T22:31:34.521243Z","shell.execute_reply":"2024-01-11T22:31:34.520235Z","shell.execute_reply.started":"2024-01-11T22:31:34.208281Z"},"trusted":true},"outputs":[],"source":["iii = img_data\n","iii = np.asarray(iii)\n","type(iii)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:26:31.457812Z","iopub.status.busy":"2024-01-11T22:26:31.457425Z","iopub.status.idle":"2024-01-11T22:26:31.466508Z","shell.execute_reply":"2024-01-11T22:26:31.465206Z","shell.execute_reply.started":"2024-01-11T22:26:31.457785Z"},"trusted":true},"outputs":[],"source":["y_train = to_categorical(np.asarray(train_data[\"label\"].factorize()[0]))\n","print(y_train[0])"]},{"cell_type":"markdown","metadata":{},"source":["# 7. Define CNN model with EfficientNetB7"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:29:52.338849Z","iopub.status.busy":"2024-01-11T22:29:52.338415Z","iopub.status.idle":"2024-01-11T22:30:15.568325Z","shell.execute_reply":"2024-01-11T22:30:15.56688Z","shell.execute_reply.started":"2024-01-11T22:29:52.338818Z"},"trusted":true},"outputs":[],"source":["efficientnet_model = Sequential()\n","\n","base_model = tf.keras.applications.EfficientNetB7(include_top=False,\n","                                            input_shape=(240,240,3),\n","                                            pooling =\"avg\",classes=15,\n","                                             weights=\"imagenet\")\n","\n","for layer in base_model.layers:\n","    layer.trainable=False\n","    \n","\n","efficientnet_model.add(base_model)\n","efficientnet_model.add(Flatten())\n","efficientnet_model.add(Dense(512, activation=\"relu\"))\n","efficientnet_model.add(Dense(15, activation=\"softmax\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:30:57.343759Z","iopub.status.busy":"2024-01-11T22:30:57.343388Z","iopub.status.idle":"2024-01-11T22:30:57.3799Z","shell.execute_reply":"2024-01-11T22:30:57.379011Z","shell.execute_reply.started":"2024-01-11T22:30:57.343732Z"},"trusted":true},"outputs":[],"source":["efficientnet_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:31:06.865838Z","iopub.status.busy":"2024-01-11T22:31:06.865449Z","iopub.status.idle":"2024-01-11T22:31:06.951669Z","shell.execute_reply":"2024-01-11T22:31:06.950737Z","shell.execute_reply.started":"2024-01-11T22:31:06.865808Z"},"trusted":true},"outputs":[],"source":["efficientnet_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# 8. Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T22:31:55.718623Z","iopub.status.busy":"2024-01-11T22:31:55.717778Z","iopub.status.idle":"2024-01-11T23:05:48.70886Z","shell.execute_reply":"2024-01-11T23:05:48.708029Z","shell.execute_reply.started":"2024-01-11T22:31:55.718585Z"},"trusted":true},"outputs":[],"source":["history = efficientnet_model.fit(iii,y_train, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:06:22.198345Z","iopub.status.busy":"2024-01-11T23:06:22.197986Z","iopub.status.idle":"2024-01-11T23:06:22.601479Z","shell.execute_reply":"2024-01-11T23:06:22.600503Z","shell.execute_reply.started":"2024-01-11T23:06:22.198316Z"},"trusted":true},"outputs":[],"source":["losses = history.history[\"loss\"]\n","plt.plot(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:06:43.142363Z","iopub.status.busy":"2024-01-11T23:06:43.141313Z","iopub.status.idle":"2024-01-11T23:06:43.554358Z","shell.execute_reply":"2024-01-11T23:06:43.553431Z","shell.execute_reply.started":"2024-01-11T23:06:43.142324Z"},"trusted":true},"outputs":[],"source":["acc = history.history['accuracy']\n","plt.plot(acc)"]},{"cell_type":"markdown","metadata":{},"source":["# 9. Model predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:07:37.024478Z","iopub.status.busy":"2024-01-11T23:07:37.024066Z","iopub.status.idle":"2024-01-11T23:07:37.03064Z","shell.execute_reply":"2024-01-11T23:07:37.029608Z","shell.execute_reply.started":"2024-01-11T23:07:37.024445Z"},"trusted":true},"outputs":[],"source":["def read_img(fn):\n","    img = Image.open(fn)\n","    return np.asarray(img.resize((160,160)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classes_dict = train_data.label.value_counts().index.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:08:49.788685Z","iopub.status.busy":"2024-01-11T23:08:49.788022Z","iopub.status.idle":"2024-01-11T23:08:49.794865Z","shell.execute_reply":"2024-01-11T23:08:49.793827Z","shell.execute_reply.started":"2024-01-11T23:08:49.788654Z"},"trusted":true},"outputs":[],"source":["def test_predict(test_image):\n","    result = efficientnet_model.predict(np.asarray([read_img(test_image)]))\n","\n","    itemindex = np.where(result == np.max(result))\n","    prediction = itemindex[1][0]\n","    print(\"probability: \" + str(np.max(result)*100) + \"%\\nPredicted class : \", classes_dict[prediction])\n","\n","    image = img.imread(test_image)\n","    plt.imshow(image)\n","    plt.title(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:08:50.218716Z","iopub.status.busy":"2024-01-11T23:08:50.218036Z","iopub.status.idle":"2024-01-11T23:08:56.914567Z","shell.execute_reply":"2024-01-11T23:08:56.913637Z","shell.execute_reply.started":"2024-01-11T23:08:50.218682Z"},"trusted":true},"outputs":[],"source":["test_predict(\"local/Human Action Recognition/test/Image_1001.jpg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:09:10.97061Z","iopub.status.busy":"2024-01-11T23:09:10.969703Z","iopub.status.idle":"2024-01-11T23:09:11.548252Z","shell.execute_reply":"2024-01-11T23:09:11.547192Z","shell.execute_reply.started":"2024-01-11T23:09:10.970575Z"},"trusted":true},"outputs":[],"source":["test_predict(\"local/Human Action Recognition/test/Image_101.jpg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:09:22.979799Z","iopub.status.busy":"2024-01-11T23:09:22.979433Z","iopub.status.idle":"2024-01-11T23:09:23.581891Z","shell.execute_reply":"2024-01-11T23:09:23.580897Z","shell.execute_reply.started":"2024-01-11T23:09:22.979773Z"},"trusted":true},"outputs":[],"source":["test_predict(\"local/Human Action Recognition/test/Image_1056.jpg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T23:10:16.978336Z","iopub.status.busy":"2024-01-11T23:10:16.977954Z","iopub.status.idle":"2024-01-11T23:10:17.624113Z","shell.execute_reply":"2024-01-11T23:10:17.623189Z","shell.execute_reply.started":"2024-01-11T23:10:16.978306Z"},"trusted":true},"outputs":[],"source":["test_predict(\"local/Human Action Recognition/test/Image_1024.jpg\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict_random_image():\n","    num = random.randint(1,5400)\n","    imgg = \"Image_{}.jpg\".format(num)\n","    train = \"local/Human Action Recognition/test/\"\n","    path = train + imgg\n","    if os.path.exists(path):\n","        test_predict(path)\n","    else:\n","        print(\"File Path not found \\nSkipping the file!!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predict_random_image()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2232355,"sourceId":3733921,"sourceType":"datasetVersion"}],"dockerImageVersionId":30635,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
